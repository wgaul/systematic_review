---
title: "Biological Records Systematic Review - Preliminary Results"
output:
  html_document: default
  html_notebook: default
  word_document: default
---

```{r, echo=F}
knitr::opts_chunk$set(echo=F, message=F, warning=T, cache=F)
```

```{r, load_data, cache = F, results='hide', warning = F}
setwd("~/Documents/Data_Analysis/UCD/systematic_review/")
library(wgutil)
library(Hmisc)
library(irr)
library(captioner)
library(knitr)
library(pander)
library(ggridges)
library(bestglm)
library(car)
library(GGally)
library(tidyverse)

diag <- F # produce exploratory & diagnostics plots & results
diag_present <- T # produce diagnostics for report to Dina

# read in data
elig <- read_csv("~/Documents/UCD/PhD_Project/systematic_review/master_eligibility_results.csv")
rev <- read_csv("./data/systematic_review_coded_results.csv")
cp <- read_csv("./data/casey_coded_results.csv")
cp_pre_cal <- read_csv("./data/casey_coded_results_pre_calibration.csv")

# remove columns which are used as visual separators with no data
if(any(grepl("X.*", colnames(rev)))) {
  rev <- rev[, -which(grepl("X.*", colnames(rev)))]
}
colnames(rev) <- make.names(colnames(rev))

# remove columns which are used as visual separators with no data - casey's coding
if(any(grepl("X.*", colnames(cp)))) {
  cp <- cp[, -which(grepl("X.*", colnames(cp)))]
}
colnames(cp) <- make.names(colnames(cp))

# remove columns which are used as visual separators with no data - casey's coding
if(any(grepl("X.*", colnames(cp_pre_cal)))) {
  cp_pre_cal <- cp_pre_cal[, -which(grepl("X.*", colnames(cp_pre_cal)))]
}
colnames(cp_pre_cal) <- make.names(colnames(cp_pre_cal))

# tidy some column names
colnames(rev)[which(
  colnames(rev) == 
    "X.if.prediction.used..prediction.performance.measure")] <- 
  "predicton.performance.measure"
colnames(cp)[which(
  colnames(cp) == 
    "X.if.prediction.used..prediction.performance.measure")] <- 
  "predicton.performance.measure"
colnames(cp_pre_cal)[which(
  colnames(cp_pre_cal) == 
    "X.if.prediction.used..prediction.performance.measure")] <- 
  "predicton.performance.measure"

rev <- rev[which(rev$coding.DONE == T), ] 
rev <- rev[which(rev$qualifies == T), ]
rev <- rev[, -which(colnames(rev) %in% c(
  "link", "inclusion.order", "other.notes", 
  "aspects.not.yet.coded", 
  "eligible.for.meta..or.publication.bias.analysis", 
  "wg.needs.to.read"))]

cp <- cp[, -which(colnames(cp) %in% c("coding.DONE", "other.notes"))]
cp_pre_cal <- cp_pre_cal[, -which(colnames(cp_pre_cal) %in% 
                                    c("coding.DONE", "other.notes"))]
```

```{r calc_temp_extent}
# calculate number of years covered by study
rev$temp_extent <- as.numeric(rev$end.year) - as.numeric(rev$start.year)
# individually assign values to studies with temporal extent < 1 year
if(diag) rev$title[rev$temp_extent == 0] 
rev$temp_extent[which(
  grepl("An assessment of bumblebee .* land use and floral.*", 
        rev$title))] <- 0.33
```

```{r make_voucher_available_column}
rev$data.type...voucher.available <- rev$data.type...museum == T |
  rev$data.type...photo == T |
  rev$data.type...audio == T | 
  rev$data.type...video ==T
```

```{r voucher_data_to_whwhwh, include = F, eval = F}
## This chunk could be turned on if I decide that:
## For the purposes of analysis, if there was a specimen available but the 
# specimen was not used at all for analysis, then, if there are no other richer
# data types, I will consider the data what, where, when-only.  I think this
# best represents the use of museum data.  I do not think this would make sense
# for other data types (e.g. if there is abundance data but the analysis only
# uses it as what, where, when) because that is a choice to strip usually 
# meaningful information.  The physical specimen is likely not meaningful for
# many analyses that use museums as a source of wh, wh, wh data.

## But as of 23 August 2018 I think I will keep the museum data as "voucher
## available" and not transform the whwhwh column.  

for(i in 1:nrow(rev)) {
  if(rev$data.type...museum[i] == T | rev$data.type...photo[i] == T | 
     rev$data.type...audio[i] == T | rev$data.type...video[i] == T) {
    # If a voucher is available
    if(rev$data.type...abundance[i] == F & 
       rev$data.type...sampling.effort.reported[i] == F & 
       rev$data.type...organized.data.collection.scheme[i] == F & 
       rev$data.type...visit.specific.covariates[i] == F & 
       rev$data.type...life.stage[i] == F) {
      # If there are no other rich data types
      if(rev$voucher.of.some.kind.necessary.for.analysis[i] == F) {
        # If the voucer was not used
        rev$data.type...what.where.when.only[i] <- TRUE
      }
    }
  }
} 
```

```{r numberingPrep}
# make functions for adding numbered captions to figures 
figs <- captioner(prefix = "Fig.") 
```

# Preliminary structure of analysis and results
This document states every question I plan to ask and shows methods, figures, tables and results text that I expect to use to answer each question in the biological records systematic review. Specific results and interpretations will change when I code the rest of the articles.

# Methods
We did a systematic review of original research published since 2014 that used biological records from Ireland and the UK.  We generated a list of relevant articles from Web of Science, Scopus, ProQuest, GoogleScholar, and the Global Biodiversity Information Facility (GBIF) website.  I evaluated each article for inclusion eligibility and coded information on [**??**] characteristics for each eligible article.  This coding was validated for a subset of articles by a second reader.  Agreement between the two readers was evaluated using [**???**].

## Study eligibility
Studies were eligible for inclusion if they met all of the following criteria:

1) original research
2) English language
3) used opportunistic biological data collected with non-standardized or semi-standardized protocols
4) included (but were not necessarily limited to) data from Ireland or the UK
5) the full text of the study was available through the UCD library online platform, Google, GoogleScholar, or ResearchGate.  
6) performs at least one analysis of the data (data papers and biotic atlases were not eligible)
7) sample size greater than 20
8) not restricted to fossil records

Grey literature was included and therefore peer review was not required.  Studies using semi-standardized data collection schemes (e.g. UK Butterfly Monitoring Scheme) were included as long as they included some opportunistic elements (e.g. locations chosen opportunistically by volunteers). Studies for which all data was collected by the study authors were excluded.  

## Article coding
### Data Type
We coded twelve variables describing aspects of data type: what, where, when only; sampling effort reported; abundance; detection / non-detection; organized monitoring scheme; visit-specific covariates; multiple datasets integrated for analysis; life stage information; museum specimen; photo; audio; video. Data types are not mutually exclusive except fot the "what where when only" data type, which cannot be true if any other data type is true.  We considered "what, where, when" as the baseline data type and considered all other data types supplementary additions to that basic data type.

~~For statistical analyses, we used only the sampling effort reported, abundance, and detection / non-detection data type variables based on *a-priori* expectations about their expected benefit in enabling inferential and predictive modelling and their expected cost in terms of complexity in collecting, recording, and storing the data.~~

For most analyses, we grouped the data types "museum specimen", "photo", "audio", and "video" into a "voucher specimen" group, but we coded them individually for in order to identify emerging trends in how vouchers are collected. 

For statistical analyses, we kept data type variables in models based on *a-priori* expectations about the variables' influence on data analysis strategy and based on expectations about different levels of complexity and effort involved in collecting, recording, and storing the data.  The data type variables we kept in models were: what, where, when only; sampling effort reported; abundance; detection / non-detection; organized monitoring scheme; visit-specific covariates; multiple datasets integrated for analysis; life stage information; voucher specimen.  

----------------------------

### Agreement between two readers (TODO)
**Dina**, do you have any suggestions about ways to quantify the agreement between two readers in how they code studies?

I used Krippendorf's *alpha* to evaluate the agreement between two readers for each of **???** variables that had been coded by two people.  

```{r inter_coder_agreement_subset_dfs}
# remove columns that aren't coded variables from casey's df
cp <- cp[, which(colnames(cp) %nin% c("link", "qualifies", "authors", 
                                      "publication", "doi", "year"))]
cp <- cp[order(cp$title), ] # order rows
cp <- cp[, order(colnames(cp))] # order columns
# put title column first
cp <- cp[, c(which(colnames(cp) == "title"), which(colnames(cp) != "title"))]

# subset my coded results to titles and columns coded by casey
mult_coded_rev <- rev[which(rev$title %in% cp$title), 
                      which(colnames(rev) %in% colnames(cp))]
mult_coded_rev <- mult_coded_rev[order(mult_coded_rev$title), ] # order rows
mult_coded_rev <- mult_coded_rev[, order(colnames(mult_coded_rev))] # order cols
mult_coded_rev <- mult_coded_rev[, c(
  which(colnames(mult_coded_rev) == "title"), 
  which(colnames(mult_coded_rev) != "title"))]

## check to make sure df rows and cols are in the same order
if(any(cp$title %nin% mult_coded_rev$title)) {
  warning("Some titles in cp are not in mult_coded_rev.")
  cp <- cp[which(cp$title %in% mult_coded_rev$title), ]
}
if(any(mult_coded_rev$title %nin% cp$title)) {
  warning("Some titles in mult_coded_rev are not in cp.")
  mult_coded_rev <- mult_coded_rev[which(mult_coded_rev$title %in%
                                           cp$title), ]
}
if(!identical(cp$title, mult_coded_rev$title)) {
  stop("Study titles in cp and mult_coded_rev are either not the same or are not in the same order.  They must be in the same order for creating the variable data frames that will be used to calculate Krippendorf's alpha.")
}
if(!identical(colnames(cp), colnames(mult_coded_rev))) {
  stop("Columns in cp and mult_coded_rev must be identical and in the same order.")
}

## convert all columns from logical to character
# for(i in 1:ncol(cp)) {
#   cp[, i] <- as.character(cp[, i][[1]])
# }
# for(i in 1:ncol(mult_coded_rev)) {
#   mult_coded_rev[, i] <- as.character(mult_coded_rev[, i][[1]])
# }
```

```{r make_dfs_of_double_coded_variables_all_studies}
## make a data frame for each double-coded variable
# each row is codings from one person
# each column is a study
dbl_coded <- list()

if(colnames(cp)[1] != "title") {stop("The first column of cp and mult_coded_rev must be the study title.")}

for(i in 2:ncol(cp)) { # awkward subsetting is b/c of tibble format
  dbl_coded[[i-1]] <- data.frame(matrix(data = c(cp[, i][[1]], 
                                                 mult_coded_rev[, i][[1]]),
                                        nrow = 2, ncol = nrow(cp), byrow = T))
}
names(dbl_coded) <- colnames(cp)[2:ncol(cp)]
```

```{r define_calibration_set}
## probably do this automated?
calibration_set <- cp_pre_cal$title

calibration_set <- c("The sensitivity of breeding songbirds to changes in seasonal timing is linked to population change but cannot be directly attributed to the effects of trophic asynchrony on productivity", 
                     "Missing native oyster (Ostrea edulis L.) beds in a European Marine Protected Area: Should there be widespread restorative management?", 
                     "The arrow points north–endemic areas and post-Devensian assembly of the British Empidoidea fauna (Insecta: Diptera)", 
                     "Changes in the geographical distribution of plant species and climatic variables on the West Cornwall peninsula (South West UK)", 
                     "Ocean current connectivity propelling the secondary spread of a marine invasive comb jelly across western Eurasia", 
                     "Congruency in fungal phenology patterns across dataset sources and scales", 
                     "N81 Tullow Footbridges Scheme & Associated Road Reconfiguration Works Appropriate Assessment Screening Report", 
                     "British phenological records indicate high diversity and extinction rates among late-summer-flying pollinators", 
                     "Population variability in species can be deduced from opportunistic citizen science records: a case study using British butterflies", 
                     "Predicting population trends using citizen science data: do subsampling methods produce reliable estimates for mammals?", 
                     "Nature protection areas of Europe are insufficient to preserve the threatened beetle Rosalia alpina (Coleoptera: Cerambycidae): evidence from species distribution models and conservation gap analysis")
```

```{r make_dfs_of_calibration_double_coded_articles}
pre_cal_list <- list()

# pre_cal_cp <- cp[which(cp$title %in% calibration_set), ]
pre_cal_rev <- mult_coded_rev[which(mult_coded_rev$title %in% calibration_set), ]

if(colnames(cal_cp)[1] != "title") {stop("The first column of cal_cp and mult_coded_rev must be the study title.")}

for(i in 2:ncol(cal_cp)) { # awkward subsetting is b/c of tibble format
  cal_list[[i-1]] <- data.frame(matrix(data = c(cal_cp[, i][[1]],
                                                 cal_rev[, i][[1]]),
                                        nrow = 2, ncol = nrow(cal_cp), byrow = T))
}
names(cal_list) <- colnames(cal_cp)[2:ncol(cal_cp)]
```

```{r make_dfs_of_post_calibration_doubl_coded_articles}
post_cal_list <- list()

post_cal_cp <- cp[which(cp$title %nin% calibration_set), ]
post_cal_rev <- mult_coded_rev[which(mult_coded_rev$title %nin% calibration_set), ]

if(colnames(post_cal_cp)[1] != "title") {stop("The first column of post_cal_cp and mult_coded_rev must be the study title.")}

for(i in 2:ncol(post_cal_cp)) { # awkward subsetting is b/c of tibble format
  post_cal_list[[i-1]] <- data.frame(matrix(data = c(post_cal_cp[, i][[1]], 
                                                     post_cal_rev[, i][[1]]),
                                            nrow = 2, ncol = nrow(post_cal_cp), 
                                            byrow = T))
}
names(post_cal_list) <- colnames(post_cal_cp)[2:ncol(post_cal_cp)]
```

```{r krippendorfs_alpha_calc}
do_kripp.alpha <- function(x, method) {
  # function to call kripp.alpha while converting dataframe x to a matrix
  # ARGS: x - data frame in which rows are observers and columns are studies
  #       method - character string of method to pass to kripp.alpha
  kripp.alpha(as.matrix(x), method = method)
}

kripp_all <- lapply(dbl_coded, FUN = do_kripp.alpha, method = "nominal")
kripp_cal <- lapply(cal_list, FUN = do_kripp.alpha, method = "nominal")
kripp_post_cal <- lapply(post_cal_list, FUN = do_kripp.alpha, method = "nominal")
```

```{r krippendorfs_alpha_summary}
boxplot(list(all = sapply(kripp_all, FUN = function(x) {x$value}), 
        calibration = sapply(kripp_cal, FUN = function(x) {x$value}), 
        post_calibration = sapply(kripp_post_cal, 
                                  FUN = function(x) {x$value})), 
     main = "Agreement for all double-coded studies and variables",
     xlab = "Krippendorf's alpha value")
```

--------------------------

## Temporal Extent

$H_a$: The mean temporal extent of studies using only what, where, when data is longer than the mean temporal extent of studies using richer data types. 

$H_0$: The mean temporal extent of studies using what, where, when-only data is the same as the mean temporal extent of studies using richer data types. 

*Proposed Test*: Linear regression with natural-log transformed time (in years) as the outcome and data types as predictors.

We used linear regression with natural-log transformed time (in years) as the response variable.  We used nine binary predictor variables indicating whether the data had the following information: 1) only what where when data, 2) sampling effort, 3) abundance, and 4) detection / non-detection, 5) organized monitoring scheme, 6) visit-specific covariates, 7) multiple datasets integrated for analysis, 8) life stage information, and 9) voucher specimen.  While the predictor variables are correlated, we kept all variables in the multiple regressin model because we are interested in the effect of each additional type of information *after accounting for other information types* (e.g. is there an additional effect of having abundance data after adjusting for whether the data came from an organized monitoring scheme).

Note that because the variables are not mutually exclusive these are each individual variables - these are not dummy variables representing a single categorical factor level "data type" variable.  

The intercept-only model in this analysis is not particularly relevant or sensible to interpret. **need to revisit this - what is intercept only model now that I include all *a-priori* data type variables?**  


```{r time_assess_correlation_predictors, fig.height=8, fig.width = 8}
### assess correlation between data type predictors ----------------------
dt_df <- rev[, which(
  colnames(rev) %in% 
    c("data.type...what.where.when.only", 
      "data.type...sampling.effort.reported", 
      "data.type...abundance", 
      "data.type...detection...non.detection", 
      "data.type...organized.data.collection.scheme", 
      "data.type...visit.specific.covariates", 
      "data.type...multiple.datasets.integrated.for.analysis", 
      "data.type...life.stage", 
      "data.type...voucher.available"))]
for(i in 1:ncol(dt_df)) {
  dt_df[, i] <- as.factor(as.character(data.frame(dt_df)[, i]))
}

print(ggpairs(dt_df, columns = 1:ncol(dt_df), 
              upper = list(discrete = "ratio"),
              lower = list(discrete = "facetbar"), 
              diag = list(discrete = "barDiag"), 
              columnLabels = c("what where when only", 
                               "sampling effort",
                               "abundance",
                               "non detection", 
                               "organized scheme", 
                               "visit specific covariates", 
                               "multiple datasets", 
                               "life stage", 
                               "voucher available"), 
              labeller = label_wrap_gen(width = 10)) + 
        ggtitle("Correlation of data type predictor variables") + 
        theme(axis.text.x = element_text(angle = 50, hjust = 1)))
  
```


```{r prepare_temporal_extent_df}
temp_extent <- select(rev, 
                      c(title, temp_extent, 
                        data.type...what.where.when.only, 
                        data.type...sampling.effort.reported, 
                        data.type...abundance,
                        data.type...detection...non.detection,
                        data.type...organized.data.collection.scheme, 
                        data.type...visit.specific.covariates, 
                        data.type...multiple.datasets.integrated.for.analysis,
                        data.type...life.stage, 
                        data.type...voucher.available)) %>%
  gather(key = "data_type", value = "dt_value", 
         data.type...what.where.when.only:data.type...voucher.available, 
         factor_key = T) %>%
  filter(dt_value == T) %>%
  group_by(data_type)

# make names prettier
temp_extent$data_type <- gsub("data.type...", "", temp_extent$data_type)

temp_extent$data_type <- factor(as.character(temp_extent$data_type), 
                            levels = c("what.where.when.only", 
                                       "sampling.effort.reported",
                                       "abundance",
                                       "detection...non.detection", 
                                       "organized.data.collection.scheme", 
                                       "visit.specific.covariates", 
                                       "multiple.datasets.integrated.for.analysis", 
                                       "life.stage", 
                                       "voucher.available"), 
                            labels = c("what where when only", 
                                       "sampling effort reported",
                                       "abundance",
                                       "non detection", 
                                       "organized scheme", 
                                       "visit specific covariates", 
                                       "multiple datasets", 
                                       "life stage", 
                                       "voucher available"))
```

Evaluate normality of raw data:
```{r temp_range_distribution}
if(diag_present) {
  # distribution of all data
 # hist(rev$temp_extent)
 # hist(rev$temp_extent[which(rev$temp_extent <= quantile(rev$temp_extent, 
 #                                                        0.90, na.rm = T))])
  ## data are not balanced
  print(table(temp_extent$data_type))
  print("Data are not balanced.")
  
  ggplot(data = temp_extent, aes(y = temp_extent, x = data_type)) + 
    geom_boxplot() +
    theme_bw() + 
    ggtitle("All data") + 
    theme(axis.text.x = element_text(angle = 330, vjust = 0.3))
  
  ggplot(data = temp_extent, aes(y = temp_extent, x = data_type)) + 
    ylim(c(0, 800)) + 
    geom_boxplot() +
    theme_bw() + 
    ggtitle("Temporal Duration after\ncutting off the 8000 year study") + 
    theme(axis.text.x = element_text(angle = 330, vjust = 0.3))
  
  ggplot(data = temp_extent, aes(x = temp_extent, y = data_type)) + 
    xlim(c(0, 800)) + 
    geom_density_ridges() +
    ggtitle("Temporal Duration after\ncutting off the 8000 year study") + 
    theme_bw()
  
  ## normality -------------------------------------
  # data very non-normal (above) but log transformation kinda fixes this
  # (reciprocal and sqrt transformations did not help)
  print(ggplot(data = temp_extent, aes(y = temp_extent, x = data_type)) + 
          geom_boxplot(varwidth = T) +
          scale_y_log10() + 
          theme_bw() + 
          ggtitle("log transformation of year\nmakes normality better") + 
          ylab("Temporal extent (years)") + 
          theme(axis.text.x = element_text(angle = 40, vjust = 0.9, 
                                           hjust = 1)))
  
  print(ggplot(data = temp_extent, aes(x = temp_extent, y = data_type)) + 
          scale_x_log10() + 
          geom_density_ridges(stat = "binline", alpha = 0.4) +
          geom_density_ridges(alpha = 0.4) + 
          xlab("Temporal extent (years)") + 
          theme_bw())
  
  if(diag) {
    for(i in unique(temp_extent$data_type)) { 
      # distribution of log(years) by data type
      hist(log(temp_extent$temp_extent)[which(temp_extent$data_type == i)])
      qqnorm(log(temp_extent$temp_extent)[which(temp_extent$data_type == i)])
      qqline(log(temp_extent$temp_extent)[which(temp_extent$data_type == i)])
    }
  }
}
```

Fit full model and evaluate residuals for assumptions of linear regression.
```{r fit_temp_extent_lm}
## fit linear regression with log-transformed years as response variable
## and each data type as a separate variable 
# fit full model
rev$log_years <- log(rev$temp_extent)
# variables added based on a-priori expectation of most to least important
time_lm_full <- lm(log_years ~ 1 + 
                     data.type...what.where.when.only + 
                     data.type...sampling.effort.reported + 
                     data.type...abundance +
                     data.type...detection...non.detection + 
                     data.type...organized.data.collection.scheme + 
                     data.type...visit.specific.covariates + 
                     data.type...multiple.datasets.integrated.for.analysis + 
                     data.type...life.stage + 
                     data.type...voucher.available,
                   data = rev) 
time_resids <- rstandard(time_lm_full) # calculate residuals
if(diag_present) {
  print("Diagnostics for full model log_years ~ all 9 data types")
  plot(time_lm_full)
  hist(time_resids, 
       main = "standardized residuals of full model for temporal extent", 
       xlab = "standardized residuals")
  boxplot(time_resids, ylab = "standardized residuals")
}
time_summary <- summary(time_lm_full)
# time_full_model_anova <- anova(time_lm_full) # not recommended because R guesses a null model
time_summary

## to interpret outcome on original scale:
# for a one-unit increase in x, the predicted value of y 
# changes by (e^beta1 - 1)*100 percent
```

```{r time_data_type_full_model_sig_test, include = F}
# Test significance of full model
m0 <- lm(log_years ~ 1, data = rev) # fit null model 
m_time_full_anova <- anova(m0, time_lm_full)
```

```{r time_data_type_test_main_effects, include = F}
## test effect of each data type predictor by comparing the full model to a
# model with that predictor removed
# 
# TODO: Does this need multiple comparison correction?

m_no_whwhwh <- lm(log_years ~ 1 + 
                    data.type...sampling.effort.reported + 
                    data.type...abundance +
                    data.type...detection...non.detection + 
                    data.type...organized.data.collection.scheme + 
                    data.type...visit.specific.covariates + 
                    data.type...multiple.datasets.integrated.for.analysis + 
                    data.type...life.stage + 
                    data.type...voucher.available,
                  data = rev)
m_no_effort <- lm(log_years ~ 1 + 
                    data.type...what.where.when.only + 
                    data.type...abundance +
                    data.type...detection...non.detection + 
                    data.type...organized.data.collection.scheme + 
                    data.type...visit.specific.covariates + 
                    data.type...multiple.datasets.integrated.for.analysis + 
                    data.type...life.stage + 
                    data.type...voucher.available,
                  data = rev)
m_no_abund <- lm(log_years ~ 1 + 
                   data.type...what.where.when.only + 
                   data.type...sampling.effort.reported + 
                   data.type...detection...non.detection + 
                   data.type...organized.data.collection.scheme + 
                   data.type...visit.specific.covariates + 
                   data.type...multiple.datasets.integrated.for.analysis + 
                   data.type...life.stage + 
                   data.type...voucher.available,
                 data = rev)
m_no_nonDet <- lm(log_years ~ 1 + 
                    data.type...what.where.when.only + 
                    data.type...sampling.effort.reported + 
                    data.type...abundance +
                    data.type...organized.data.collection.scheme + 
                    data.type...visit.specific.covariates + 
                    data.type...multiple.datasets.integrated.for.analysis + 
                    data.type...life.stage + 
                    data.type...voucher.available,
                  data = rev)
m_no_scheme <- lm(log_years ~ 1 + 
                    data.type...what.where.when.only + 
                    data.type...sampling.effort.reported + 
                    data.type...abundance +
                    data.type...detection...non.detection + 
                    data.type...visit.specific.covariates + 
                    data.type...multiple.datasets.integrated.for.analysis + 
                    data.type...life.stage + 
                    data.type...voucher.available,
                  data = rev)
m_no_visitCovs <- lm(log_years ~ 1 + 
                       data.type...what.where.when.only + 
                       data.type...sampling.effort.reported + 
                       data.type...abundance +
                       data.type...detection...non.detection + 
                       data.type...organized.data.collection.scheme + 
                       data.type...multiple.datasets.integrated.for.analysis + 
                       data.type...life.stage + 
                       data.type...voucher.available,
                     data = rev)
m_no_multData <- lm(log_years ~ 1 + 
                      data.type...what.where.when.only + 
                      data.type...sampling.effort.reported + 
                      data.type...abundance +
                      data.type...detection...non.detection + 
                      data.type...organized.data.collection.scheme + 
                      data.type...visit.specific.covariates + 
                      data.type...life.stage + 
                      data.type...voucher.available,
                    data = rev)
m_no_lifeStage <- lm(log_years ~ 1 + 
                       data.type...what.where.when.only + 
                       data.type...sampling.effort.reported + 
                       data.type...abundance +
                       data.type...detection...non.detection + 
                       data.type...organized.data.collection.scheme + 
                       data.type...visit.specific.covariates + 
                       data.type...multiple.datasets.integrated.for.analysis + 
                       data.type...voucher.available,
                     data = rev)
m_no_voucher <- lm(log_years ~ 1 + 
                     data.type...what.where.when.only + 
                     data.type...sampling.effort.reported + 
                     data.type...abundance +
                     data.type...detection...non.detection + 
                     data.type...organized.data.collection.scheme + 
                     data.type...visit.specific.covariates + 
                     data.type...multiple.datasets.integrated.for.analysis + 
                     data.type...life.stage,
                   data = rev)

indiv_mods_time <- list(m_no_whwhwh, m_no_effort, m_no_abund, m_no_nonDet, 
                        m_no_scheme, m_no_visitCovs, m_no_multData, 
                        m_no_lifeStage, m_no_voucher)
```


---------------------

## Authors and Data Providing Institutions (TODO)

**Who choses to use biological records data?**

$H_a$: The first author is more likely to use data held by their own institution than by other institutions.

$H_0$: The number of studies with a lead author from the institution that provided the data is the same as expected by chance.

*Proposed Test*: Permutation test of lead author institutions.  

----------------------

____________________________________________________________________________

# Results

## Search results (TODO)
The search returned `r nrow(elig)` potentially relevant studies, of which we have evaluated `r sum(!is.na(elig$qualifies))` for eligibility, and judged `r length(which(elig$qualifies == TRUE))` to be eligible for inclusion in the scoping review.  One reader has coded `r nrow(rev)` articles and a second reader has coded [???] of those. This preliminary analysis uses the `r nrow(rev)` articles coded so far.

 




### Results for Time

```{r print_time_anova}
m_time_full_anova
```

```{r print_time_individual_predictor_significance}
for(i in 1:length(indiv_mods_time)) { 
  print(anova(indiv_mods_time[[i]], time_lm_full))
}
```

The overall model using supplementary data types to predict the natural log of temporal extent of study (in years) was significant ($F_{`r format(round(m_time_full_anova$Df[2], digits = 2), scientific = F)`, `r format(round(m_time_full_anova$Res.Df[2], digits = 2), scientific = F)`}$ = `r format(round(m_time_full_anova$F[2], digits = 2), scientific = F)`, p = `r format(round(m_time_full_anova[6][[1]][2], digits = 4), scientific = F)`, Adjusted $R^2%$ = `r format(round(time_summary$adj.r.squared, digits = 2), scientific = F)`).  

If the overall model is significant, I will individually test whether each variable has a significant effect after accounting for the other variables.  I will interpret the effect direction and effect size of all variables in the context of the full model even if the variables are not significant on their own.
 
The expected temporal extent covered by a study that uses only "what, where, when" data is `r round(exp((time_lm_full$coefficients[1] + time_lm_full$coefficients[2])), digits = 1)` years. 

The expected temporal extent of studies is shorter for studies that include sampling effort information than for studies that use only "what, where, when" data (*p* = `r format(round(time_summary$coefficients[2, 4], digits = 3), scientific = F)`).  The effects of additional information on detection / non-detection and abundance were not significant after accounting for the effects of the other data types.  The signs of the effects of sampling effort information and detection / non-detection information were both negative, as expected.  However, the sign of the effect for abundance information was unexpectedly positive.  This may be because abundance is correlated with detection/non-detection and sampling effort.  When I fit a model with only the intercept and the abundance data type, the direction of the effect of abundance data was negative as expected.    

```{r time_extent_results_plot}
## TODO: need to hand-annotate R2 and p-value in plot
temp_extent$sig_different_from_WhWhWh <- temp_extent$data_type %in% 
                                       c("sampling effort reported")
print(ggplot(data = temp_extent, aes(y = temp_extent, x = data_type)) + #, color = sig_different_from_WhWhWh
        geom_boxplot(varwidth = T) +
        scale_y_log10() + 
        xlab("Data Type") + 
        ylab("Temporal Extent of Study (years)") + 
        annotate("text", x = 3, y = 2600, 
                 label = "paste(\"Adjusted \", 
                 italic(R) ^ 2, \" = 0.3\")", 
                parse = TRUE) + 
  annotate("text", x = 3, y = 1200, 
           label = "paste(\"Overall model significance \", 
                 italic(p), \" = 0.012\")", 
           parse = TRUE) +
        theme_bw() + 
        scale_color_discrete(name = "Significantly Different from\nWhat, Where, When-only\nstudies (alpha = 0.1 level)") + 
        theme(axis.text.x = element_text(angle = 330, vjust = 1, hjust = 0)) 
)
```

```{r time_extent_results_plot_for_presentation_slide, eval = F, include = F}
## This code is to be run in the console for making plot to be exported as jpg for slides
## TODO: need to hand-annotate R2 and p-value in plot
t_size = 22 # plot text size
ggplot(data = temp_extent, aes(y = temp_extent, x = data_type)) + #, color = sig_different_from_WhWhWh
  geom_boxplot(varwidth = T) +
  scale_y_log10() + 
  xlab("Data Type") + 
  ylab("Temporal Extent of Study (years)") + 
  # annotate("text", x = 3, y = 140, 
  #          label = "paste(\"Adjusted \", 
  #                italic(R) ^ 2, \" = 0.27\")", 
  #          parse = TRUE, 
  #          size = t_size - 15) + 
  annotate("text", x = 3, y = 1400, 
           label = "paste(\"Overall model significance \", 
                 italic(p), \" = 0.012\")", 
           parse = TRUE, 
           size = t_size - 14) +
  theme_bw() + 
  scale_color_discrete(name = "Significantly Different from\nWhat, Where, When-only\nstudies (alpha = 0.1 level)") + 
  theme(axis.text.x = element_text(angle = 330, vjust = 1, hjust = 0), 
        text = element_text(size = t_size)) 
```


## Study Question Paradigm

**What is the most popular study question paradigm?**

$H_a$: Some broad study question paradigms are more common than others in studies using biological records.

$H_0$: The number of studies pursuing each of the broad study question paradigms is the same.

*Proposed Test* One Poisson regression with study question paradigm as predictor. 

```{r make_study_question_paradigm_tibble}
paradigm_df <- select(rev, title, individual.species.analysis, 
                      community.analysis) %>%
  gather(key = "paradigm", value = "used", individual.species.analysis:
           community.analysis) %>%
  filter(used == TRUE)

table(paradigm_df$paradigm)
paste0("Studies that are neither community nor individual sp analyses: ", 
       length(which(rev$community.analysis == F & 
                      rev$individual.species.analysis == F)))
```

**What data types are used for each study question paradigm?**
[ descriptive results only ] 

```{r make_study_question_paradigm_by_dataType_tibble}
paradigm_data_df <- select(rev, title, individual.species.analysis, 
                      community.analysis, data.type...what.where.when.only, 
                      data.type...sampling.effort.reported, 
                      data.type...detection...non.detection, 
                      data.type...abundance) %>%
  gather(key = "paradigm", value = "parad_used", individual.species.analysis:
           community.analysis) %>%
  filter(parad_used == TRUE) %>%
  gather(key = "data_type", value = "dat_used", 
         data.type...what.where.when.only:data.type...abundance) %>%
  filter(dat_used == TRUE)

paradigm_data_df$data_type <- gsub("data.type...what.where.when.only", 
                                   "what, where, when only", 
                                   paradigm_data_df$data_type)
paradigm_data_df$data_type <- gsub("data.type...sampling.effort.reported", 
                                   "sampling effort", 
                                   paradigm_data_df$data_type)
paradigm_data_df$data_type <- gsub("data.type...detection...non.detection", 
                                   "detection / non-detection", 
                                   paradigm_data_df$data_type)
paradigm_data_df$data_type <- gsub("data.type...abundance", 
                                   "abundance", 
                                   paradigm_data_df$data_type)
paradigm_data_df$paradigm <- gsub("community.analysis", 
                                   "community", 
                                   paradigm_data_df$paradigm)
paradigm_data_df$paradigm <- gsub("individual.species.analysis", 
                                   "individual species", 
                                   paradigm_data_df$paradigm)

kable(table(paradigm_data_df$data_type, paradigm_data_df$paradigm))
```


## Specific Study Focus

Descriptive stats for studies focusing on policy or alien species, testing ecological theory, and testing methods of data correction.

```{r specific_question_by_paradigm_bar_plot}
qt_df <- select(rev, "title", 
                "species.richness", "diversity", 
                "distribution", "abundance", "phenology") 
names(qt_df)[2:6] <- c("species.richness", "diversity", 
                        "distribution", "abundance", "phenology")

qt_df <- gather(qt_df, key = "study_question", value = "v_2", 
                species.richness, diversity, distribution, abundance, 
                phenology,
                factor_key = T) %>%
  filter(v_2 == TRUE) %>%
  group_by(study_question) %>%
  summarise(count = n()) %>%
  mutate(percent = (count/sum(count)) * 100) %>%
  mutate(paradigm = str_replace_all(study_question, 
                                    c("species.richness|diversity" = 
                                        "community", 
                                      "distribution|abundance|phenology" = 
                                        "individual species"))) 

ggplot(data = qt_df, 
       aes(x = factor(study_question, 
                      levels = c("species.richness", "diversity", 
                                 "distribution", "phenology", "abundance"), 
                      labels = c("species richness", "diversity", 
                                 "distribution", "phenology", "abundance")), 
           y = percent, 
           fill = paradigm)) + 
  geom_bar(stat = "identity") + 
  scale_fill_brewer() + 
  xlab("Study Focus") + 
  ylab("Percent of Studies") + 
  theme_bw()
```

```{r specific_question_multi_paradigm_bar_plot}
qt_df <- select(rev, "title", "methodology.development.or.analysis", 
                "testing.macro.or.ecological.theory", "trends.over.time") 
names(qt_df)[2:4] <- c("methodology", "testing.theory", "temporal.trends")

qt_df <- gather(qt_df, key = "study_question", value = "v_2", 
                temporal.trends,testing.theory, methodology,  
         factor_key = T) %>%
  filter(v_2 == TRUE) %>%
  group_by(study_question) %>%
  summarise(count = n()) %>%
  mutate(percent = (count/sum(count)) * 100)

ggplot(data = qt_df, 
       aes(x = factor(study_question, 
                      levels = c("temporal.trends", "methodology",
                                 "testing.theory"), 
                      labels = c("temporal trends", "methodology",
                                 "testing theory")), 
           y = percent)) + 
  geom_bar(stat = "identity") + 
  scale_fill_brewer() + 
  xlab("Study Focus") + 
  ylab("Percent of Studies") + 
  theme_bw()
```



_________________________________________________________________________
### Old versions below here

## Types of questions  
Analyses may appear in this table or graph more than once.  For example, a study proposing a new method for estimating species richness and then using that method to test predictions about a productivity/richness relationship would appear in the counts in three columns.

```{r questions_by_data_type}
qt_df <- select(rev, "title", "year", "methodology.development.or.analysis", 
                "distribution", "abundance", "phenology", 
                "testing.macro.or.ecological.theory", "trends.over.time", 
                "data.type...what.where.when.only", 
                "data.type...detection...non.detection", 
                "data.type...abundance", "data.type...sampling.effort.reported", 
                "data.type...organized.data.collection.scheme") 
names(qt_df)[3:8] <- c("methodology", "distribution", "abundance",
                        "phenology", "testing.theory", "temporal.trends")

qt_df <- gather(qt_df, key = "study_question", value = "v_1", 
                methodology:temporal.trends, factor_key = T) %>%
  filter(v_1 == TRUE) %>%
  gather(key = "data.type", value = "v_2", 
         data.type...what.where.when.only:
           data.type...organized.data.collection.scheme, 
         factor_key = T) %>%
  filter(v_2 == TRUE)


kable(table(qt_df$data.type, qt_df$study_question), 
      caption = "The types of questions addressed by studies that use biological records, according to what type of data they use.")

### testing stuff
chisq.test(table(qt_df$data.type, qt_df$study_question), simulate.p.value = T)
```

```{r}
qt_df <- select(rev, "title", "year", "methodology.development.or.analysis", 
                "individual.species.analysis", "community.analysis", 
                "compiled.individual.species.analysis", "distribution", 
                "abundance", "phenology", "testing.macro.or.ecological.theory", 
                "trends.over.time") 
names(qt_df)[3:10] <- c("methodology", "individual.species", "community", 
                        "compiled.individual", "distribution", "abundance",
                        "phenology", "testing.theory")

qt_df <- gather(qt_df, key = "population", value = "v_1", individual.species, 
                compiled.individual, community, factor_key = T) %>%
  filter(v_1 == TRUE) %>%
  gather(key = "study_question", value = "v_2", distribution, abundance, 
         phenology, testing.theory, methodology, trends.over.time, 
         factor_key = T) %>%
  filter(v_2 == TRUE)


kable(table(qt_df$study_question, qt_df$population) / length(unique(qt_df$title)), digits = 2, 
      caption = "The types of questions addressed by studies that use biological records.  Values are the proportion of all studies.  Study populations are columns, topic of the study is in rows.")
```




## Taxonomic Group
```{r}
taxa <- select(rev, title, year, taxonomic.group, distribution, abundance, 
               phenology, testing.macro.or.ecological.theory, trends.over.time)

tax_names <- unlist(strsplit(taxa$taxonomic.group, "; "))
tax_names <- unique(tax_names)
tax_names <- tax_names[which(!is.na(tax_names))]
tax_names <- tax_names[order(tax_names)]

temp_df <- data.frame(matrix(nrow = nrow(taxa), ncol = length(tax_names)))
colnames(temp_df) <- tax_names
taxa <- cbind(taxa, temp_df)
rm(temp_df) 

for(i in 1:nrow(taxa)) {
  groups <- taxa$taxonomic.group[i]
  groups <- unlist(strsplit(groups, "; "))
  taxa[i, which(colnames(taxa) %in% groups)] <- T
}

taxa <- gather(taxa, key = "tax_group", value = "value", 
               all:wasps) %>%
  filter(value == T) 

table(taxa$tax_group)[order(table(taxa$tax_group), decreasing = T)]
```

```{r}
if(diag) {
  taxa <- gather(taxa, key = "question", value = "v_2", 
                 distribution:trends.over.time, factor_key = T) %>%
    filter(v_2 == T)
  
  table(taxa$tax_group, taxa$question)
}
```
Above is good.  Need to simplify taxonomic groups.  Might not end up using this table, b/c the patterns it shows probably have more to do with the type of data (abundance, semi-structure) than taxonomic group.  So, butterflies don't lend themselves to abundance and phenology studies, but the monitoring scheme used for butterflies does lend itself to those types of analyses.


--------------------------------------------------------------------

## Results format by data type
$H_01$: Different types of biological records data are not analyzed with different broad analysis approaches.

$H_a1$: Different types of biological records data are analyzed with different broad analysis approaches.

$H_02$: wh,wh,wh-only data is not analyzed with a different broad analysis approach than other data types.

$H_a2$: wh,wh,wh-only data is analyzed with inference and/or prediction less often than richer data are.  

$H_03$: The ?rate? at which wh,wh,wh-only data is analyzed with prediction is not greater than for other data types.

$H_a3$: The ?rate? at which wh,wh,wh-only data is analyzed with prediction is greater than for richer data types.

```{r analysis_approach_data_prep}
rf <- select(rev, c(title, data.type...what.where.when.only:
                      results.type...descriptive.only)) %>%
  gather(key = "data_type", value = "v_1", 
         data.type...what.where.when.only:data.type...detection...non.detection, 
         data.type...abundance:data.type...museum, 
         factor_key = T) %>%
  filter(v_1 ==T) %>%
  gather(key = "results_format", value = v_2, 
         results.type...inference:results.type...descriptive.only, 
         factor_key = T) %>%
  filter(v_2 == T)

# make names prettier
rf$results_format <- gsub("results.type...", "", rf$results_format)
rf$data_type <- gsub("data.type...", "", rf$data_type)

rf$results_format <- factor(as.character(rf$results_format), 
                            levels = c("inference", "prediction", "descriptive.only"), 
                            labels = c("inference", "prediction", "descriptive only"),
                            ordered = T)
```

```{r analysis_approach_by_data_type_assumptions_poisson_reg}
if(diag) {
  table(rf$data_type, rf$results_format)
  hist(table(rf$data_type, rf$results_format)) # doesn't look poisson-y
  
  addmargins(table(rf$data_type, rf$results_format))
  
  # check unconditional mean and variance - doesn't look the same
  mean(as.numeric(table(rf$data_type, rf$results_format)))
  var(as.numeric(table(rf$data_type, rf$results_format))) 

  
}
```

```{r resultsFormatByDataType}


if(diag) {
  pander(table(rev$results.type...descriptive.only), caption = "Descriptive Only Results (need at least 10 events/non evenst per predictor)")
}

dt_table <- table(rf$data_type)
names(dt_table) <- c("What, Where,\nWhen", "Abundance", "Known\nEffort", 
                     "Semi-\nStructured", "Visit-specific\nCovariates", 
                     "museum\nspecimen")
# pander(dt_table, caption = "Table of the gathered data_type column (compare to number of studies included)", keep.line.breaks = T)


kable(table(rf$data_type, rf$results_format), 
      caption = "Results formats produced using different types of data (this is counting studies, not counting analyses).  Is there a chi-squared-type test for when grouping variable categories are not mutually exclusive?")

```




Above looks ok, but probably need to do a chi-squared test or something to compare expected v. observed counts.  Or do glm with inference & hypothesis testing (or H testing, inference, and prediction) as positive class, “descriptive” as negative class, and data type as categorical predictors?  

### $H_02$

```{r results_by_data}
rev$quantitative <- rev$results.type...hypothesis.testing == T |
  rev$results.type...inference == T | rev$results.type...prediction == T

long_rev <- select(rev, title, quantitative, data.type...what.where.when.only:
                     data.type...detection...non.detection, 
                   data.type...sampling.effort.reported:data.type...museum) %>%
  gather(key = "data_type", value = "v_1", 
         data.type...what.where.when.only:data.type...museum) %>%
  filter(v_1 == T)

long_rev$quantitative <- gsub("TRUE", "inference/prediction", as.character(long_rev$quantitative))
long_rev$quantitative <- gsub("FALSE", "descriptive", as.character(long_rev$quantitative))
kable(table(long_rev$data_type, long_rev$quantitative))

```

```{r, echo = T}
if(diag) {
  table(rev$data.type...what.where.when.only)
  table(rev$data.type...abundance)
  table(rev$data.type...detection...non.detection)
  table(rev$data.type...sampling.effort.reported)
  table(rev$data.type...organized.data.collection.scheme)
  table(rev$data.type...visit.specific.covariates)
  table(rev$data.type...museum)
}
```

```{r fit_glm_analysis_approach}
results_data_model <- glm(quantitative ~ 
                            as.factor(data.type...what.where.when.only) + 
                            as.factor(data.type...abundance) + 
                            as.factor(data.type...detection...non.detection) + 
                            as.factor(data.type...sampling.effort.reported) + 
                            as.factor(data.type...organized.data.collection.scheme) + 
                            as.factor(data.type...visit.specific.covariates) + 
                            as.factor(data.type...museum), 
                          family = binomial, 
                          data = rev)
```

```{r glm_results}
# one_cov_mod <- glm(quantitative ~ data.type...what.where.when.only + 
#                             data.type...abundance, 
#                           family = binomial, 
#                           data = rev)

# summary(results_data_model)
# library(car)
# vif(results_data_model)
```











